{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate the Data Matrix and the Label vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9120\n",
            "9120\n",
            "(125, 45)\n"
          ]
        }
      ],
      "source": [
        "paths = []\n",
        "range_of_a = [str(i).zfill(2) for i in np.arange(1, 20, 1)]\n",
        "range_of_p = [str(i).zfill(1) for i in np.arange(1, 9, 1)]\n",
        "range_of_s = [str(i).zfill(2) for i in np.arange(1, 61, 1)]\n",
        "\n",
        "labels = []\n",
        "for a in range_of_a:\n",
        "    for p in range_of_p:\n",
        "        for s in range_of_s:\n",
        "            labels.append(int(a))\n",
        "            paths.append(f\"dataset/a{a}/p{p}/s{s}.txt\")\n",
        "print(len(paths))\n",
        "print(len(labels))\n",
        "dummy = pd.read_csv(paths[70], header=None)\n",
        "print(dummy.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1: Mean of each file is a data point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7296, 45)\n",
            "(1824, 45)\n",
            "(7296, 1)\n",
            "(1824, 1)\n"
          ]
        }
      ],
      "source": [
        "def method_1():\n",
        "    no_rows=len(paths)\n",
        "    X_train=np.zeros((19*8*48,45))\n",
        "    X_test=np.zeros((19*8*12,45))\n",
        "    y_train=np.zeros((19*8*48,1))\n",
        "    y_test=np.zeros((19*8*12,1))\n",
        "    test_index=0\n",
        "    train_index=0\n",
        "    for i in range(no_rows):\n",
        "        data = pd.read_csv(paths[i], header=None)\n",
        "        if((i%60)<48):\n",
        "            X_train[train_index]=np.mean(data.values, axis=0)\n",
        "            y_train[train_index]=labels[i]\n",
        "            train_index+=1\n",
        "        else:\n",
        "            X_test[test_index]=np.mean(data.values, axis=0)\n",
        "            y_test[test_index]=labels[i]\n",
        "            test_index+=1\n",
        "    return X_train,X_test,y_train,y_test\n",
        "X_train_1,X_test_1,y_train_1,y_test_1=method_1()\n",
        "print(X_train_1.shape)\n",
        "print(X_test_1.shape)\n",
        "print(y_train_1.shape)\n",
        "print(y_test_1.shape) \n",
        "\n",
        "   \n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2: Flattening each file and reduces dimensions using PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9500287183317996\n",
            "(7296, 605)\n",
            "(1824, 605)\n",
            "(7296, 1)\n",
            "(1824, 1)\n"
          ]
        }
      ],
      "source": [
        "def method_2():\n",
        "    no_rows=len(paths)\n",
        "    X_train=np.zeros((19*8*48,125*45))\n",
        "    X_test=np.zeros((19*8*12,125*45))\n",
        "    y_train=np.zeros((19*8*48,1))\n",
        "    y_test=np.zeros((19*8*12,1))\n",
        "    test_index=0\n",
        "    train_index=0\n",
        "    for i in range(no_rows):\n",
        "        data = pd.read_csv(paths[i], header=None)\n",
        "        if((i%60)<48):\n",
        "            X_train[train_index]=data.values.flatten()\n",
        "            y_train[train_index]=labels[i]\n",
        "            train_index+=1\n",
        "        else:\n",
        "            X_test[test_index]=data.values.flatten()\n",
        "            y_test[test_index]=labels[i]\n",
        "            test_index+=1\n",
        "    pca=PCA(n_components=0.95)\n",
        "    X_train=pca.fit_transform(X_train)\n",
        "    print(np.sum(pca.explained_variance_ratio_))\n",
        "    X_test=pca.transform(X_test)        \n",
        "    return X_train,X_test,y_train,y_test\n",
        "X_train,X_test,y_train,y_test=method_2()\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
