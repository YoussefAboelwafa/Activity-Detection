{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from DataMatrix import generate_data_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (7296, 45)\n",
      "y_train shape:  (7296,)\n",
      "X_test shape:  (1824, 45)\n",
      "y_test shape:  (1824,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = generate_data_matrix(method=\"mean\")\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DBSCAN(X, min_samples, eps):\n",
    "    # Initialize labels\n",
    "    labels = np.zeros(X.shape[0])\n",
    "\n",
    "    # C is the cluster counter\n",
    "    C = 0\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        # Skip if already labeled\n",
    "        if labels[i] != 0:\n",
    "            continue\n",
    "\n",
    "        # Find neighbors within eps\n",
    "        neighbors = np.where(np.linalg.norm(X - X[i], axis=1) <= eps)[0]\n",
    "\n",
    "        # Mark as noise\n",
    "        if len(neighbors) < min_samples:\n",
    "            labels[i] = -1\n",
    "            continue\n",
    "\n",
    "        # New cluster\n",
    "        C += 1\n",
    "\n",
    "        # Assign cluster label to point\n",
    "        labels[i] = C\n",
    "\n",
    "        # Set of points to expand\n",
    "        S = list(neighbors)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(S):\n",
    "            j = S[i]\n",
    "            if labels[j] == -1:\n",
    "                labels[j] = C\n",
    "            elif labels[j] == 0:\n",
    "                labels[j] = C\n",
    "                neighbors_j = np.where(np.linalg.norm(X - X[j], axis=1) <= eps)[0]\n",
    "                if len(neighbors_j) >= min_samples:\n",
    "                    S += list(set(neighbors_j) - set(S))\n",
    "            i += 1\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def map_labels(y_true, y_pred):\n",
    "    # Create a confusion matrix\n",
    "    D = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Swap the rows and columns of the confusion matrix to match the labels\n",
    "    rows, cols = linear_sum_assignment(D, maximize=True)\n",
    "\n",
    "    # Create a dictionary to map the labels\n",
    "    label_map = {col: row for row, col in zip(rows, cols)}\n",
    "\n",
    "    # Map the labels in y_pred, skipping over any points that have a label of -1\n",
    "    y_pred = np.array([label_map[label] if label != -1 else -1 for label in y_pred])\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Map the labels\n",
    "n_samples = np.arange(0.1, 5, 0.1)\n",
    "eps = np.arange(1, 10)\n",
    "print(len(n_samples)* len(eps))\n",
    "\n",
    "for sample in n_samples:\n",
    "    for e in eps:\n",
    "        y_pred = get_DBSCAN(X_train, sample, e)\n",
    "        y_pred_mapped = map_labels(y_train, y_pred)\n",
    "\n",
    "        # Compute the accuracy\n",
    "        percision = precision_score(y_train, y_pred_mapped, average=\"weighted\")\n",
    "        recall = recall_score(y_train, y_pred_mapped, average=\"weighted\")\n",
    "        f1 = f1_score(y_train, y_pred_mapped, average=\"weighted\")\n",
    "\n",
    "        # Print the accuracy\n",
    "        print(f\"n_samples: {sample} eps: {e}\")\n",
    "        print(f\"Percision: {percision * 100:.2f}%\")\n",
    "        print(f\"Recall: {recall * 100:.2f}%\")\n",
    "        print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
